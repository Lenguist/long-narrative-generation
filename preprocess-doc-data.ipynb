{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming all CSV files are in the 'annotations' directory\n",
    "directory_path = \"doc_outputs/annotations\"\n",
    "\n",
    "\n",
    "# List of your CSV files\n",
    "csv_files = [\n",
    "    'ablations/doc_docnocontrol.csv',\n",
    "    'ablations/doc_docnooutline.csv',\n",
    "   # 'detailed_relevance/doc_docnocontrol_detailedrelevance.csv',\n",
    "   # 'interactive/doc_re3_interactive.csv',\n",
    "    'main/doc_re3.csv',\n",
    "    'main/doc_rollinggpt.csv',\n",
    "    'main/doc_rollingopt.csv'\n",
    "]\n",
    "\n",
    "# Read each CSV file and append it to a list\n",
    "dataframes_list = []\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dataframes_list, ignore_index=True)\n",
    "\n",
    "# Now `combined_df` is a single DataFrame containing all the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used for  visualization\n",
    "def abridge_text(passage):\n",
    "    # Remove any occurrences of '\\n\\n'\n",
    "    passage = passage.replace('\\n\\n', ' ')\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = passage.split('.')\n",
    "\n",
    "    # Initialize variables\n",
    "    abridged_text = []\n",
    "    word_count = 0\n",
    "    sentence_count = 0\n",
    "\n",
    "    # Iterate through sentences\n",
    "    for sentence in sentences:\n",
    "        # Count words in the current sentence\n",
    "        words_in_sentence = len(sentence.split())\n",
    "        word_count += words_in_sentence\n",
    "\n",
    "        # Increment sentence counter\n",
    "        sentence_count += 1\n",
    "\n",
    "        # Check if it's the third sentence\n",
    "        if sentence_count % 10 == 1:\n",
    "            # If we have counted words from previous sentences, add them before this sentence\n",
    "            if word_count - words_in_sentence > 0:\n",
    "                abridged_text.append(f\"... [{word_count - words_in_sentence} words]\")\n",
    "            # Add the current sentence\n",
    "            abridged_text.append(sentence.strip())\n",
    "            # Reset word count\n",
    "            word_count = words_in_sentence\n",
    "\n",
    "    # Handle the case where the last sentence(s) were not added\n",
    "    if sentence_count % 3 != 1:\n",
    "        abridged_text.append(f\"... [{word_count} words]\")\n",
    "\n",
    "    # Join the abridged sentences back into a string\n",
    "    return '. '.join(abridged_text)\n",
    "\n",
    "# Example usage\n",
    "text = \"this was a great day. How are you. I am great. Are you great? Yeah i am fine, but i lost my bike. Oh that sucks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate dataset statistics\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named df and is already loaded with the data\n",
    "df = combined_df\n",
    "# Calculate the average word count of 'premise'\n",
    "avg_premise_length = df['premise'].apply(lambda x: len(x.split())).mean()\n",
    "\n",
    "# Calculate the average word count of 'outline_item'\n",
    "avg_outline_item_length = df['outline_item'].apply(lambda x: len(x.split())).mean()\n",
    "\n",
    "# Calculate the average word count of 'passage1'\n",
    "avg_passage1_length = df['passage1'].apply(lambda x: len(x.split())).mean()\n",
    "\n",
    "# Calculate the average word count of 'passage2'\n",
    "avg_passage2_length = df['passage2'].apply(lambda x: len(x.split())).mean()\n",
    "\n",
    "print(f\"Average word count of premise: {avg_premise_length:.2f}\")\n",
    "print(f\"Average word count of outline item: {avg_outline_item_length:.2f}\")\n",
    "print(f\"Average word count of passage1: {avg_passage1_length:.2f}\")\n",
    "print(f\"Average word count of passage2: {avg_passage2_length:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame containing the reviewer preferences\n",
    "\n",
    "# Define a mapping function\n",
    "def map_preference_to_score(preference):\n",
    "    if preference == 'Passage A':\n",
    "        return \"story1\"\n",
    "    elif preference == 'Passage B':\n",
    "        return \"story2\"\n",
    "    else:  # 'Neither', 'Both', or any other response that does not indicate a clear preference\n",
    "        return 0\n",
    "\n",
    "# List the columns that contain the questions\n",
    "question_columns = [\n",
    "    'Which passage seems more interesting?',\n",
    "    'Which passage has a more coherent overall plot?',\n",
    "    'Which passage is better focused on the given sub-event?'\n",
    "]\n",
    "\n",
    "# Apply the mapping function to each question column\n",
    "for column in question_columns:\n",
    "    combined_df[column + ' Score'] = combined_df[column].apply(map_preference_to_score)\n",
    "\n",
    "# Now df has new columns with the scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with relevance score\n",
    "df_relevance = combined_df[['outline_item', 'passage1', 'passage2', 'Which passage is better focused on the given sub-event? Score']]\n",
    "df_relevance.columns = ['premise', 'story1', 'story2', 'relevance_preference']\n",
    "\n",
    "# DataFrame with coherence score\n",
    "df_coherence = combined_df[['outline_item', 'passage1', 'passage2', 'Which passage has a more coherent overall plot? Score']]\n",
    "df_coherence.columns = ['premise', 'story1', 'story2', 'coherence_preference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where relevance score is zero\n",
    "df_relevance = df_relevance.loc[df_relevance['relevance_preference'] != 0]\n",
    "df_relevance = df_relevance.reset_index(drop=True)\n",
    "# Drop rows where coherence score is zero\n",
    "df_coherence = df_coherence.loc[df_coherence['coherence_preference'] != 0]\n",
    "df_coherence = df_coherence.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths should be different because we drop different rows\n",
    "print(len(df_relevance))\n",
    "print(len(df_coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "csv_file_path = 'relevance_human_data.csv'\n",
    "df_relevance.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Read the CSV file back into a DataFrame\n",
    "df_reloaded = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the reloaded DataFrame\n",
    "df_reloaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file\n",
    "csv_file_path = 'coherence_human_data.csv'\n",
    "df_coherence.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Read the CSV file back into a DataFrame\n",
    "df_reloaded = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the reloaded DataFrame\n",
    "df_reloaded.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
